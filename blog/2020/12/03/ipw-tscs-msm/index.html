<!DOCTYPE html>
<html lang="en"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Shagun Jhaver">
    <meta name="description" content="Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments">
    <meta name="keywords" content="r, tidyverse, causal inference, DAGs, do calculus, inverse probability weighting">
    <meta name="generator" content="Hugo 0.88.1" />

    <title>
  Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data | Shagun Jhaver
</title>

    <link rel="canonical" href="https://www.shagunjhaver.com/blog/2020/12/03/ipw-tscs-msm/">
    <link rel="alternate" type="application/atom+xml" title="Blog Posts" href="https://www.shagunjhaver.com/atom.xml">
    <link rel="alternate" type="application/json" title="JSON Feed" href="https://www.shagunjhaver.com/feed.json">

    <link rel="openid2.provider" href="https://www.google.com/accounts/o8/ud?source=profiles">
    <link rel="openid2.local_id" href="https://www.google.com/profiles/andrewheiss">

    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image" content="https://www.shagunjhaver.com/profiles/twitter-card-large.png?v=1"/>
    <meta name="twitter:site" content="@shagunjhaver"/>
    <meta name="twitter:title" content="Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data"/>
    <meta name="twitter:creator" content="@shagunjhaver"/>
    <meta name="twitter:description" content="Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments"/>


    <meta property="og:title" content="Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data" />
<meta property="og:description" content="Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.shagunjhaver.com/blog/2020/12/03/ipw-tscs-msm/" />
<meta property="og:image" content="https://www.shagunjhaver.com/profiles/twitter-card-large.png"/>
<meta property="article:published_time" content="2020-12-03T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-12-03T00:00:00+00:00" />

<meta property="article:author" content="https://www.facebook.com/shagun.jhaver" />
<meta property="article:publisher" content="https://www.facebook.com/shagun.jhaver" />
<meta property="article:section" content="blog" />
<meta property="article:tag" content="r" />
<meta property="article:tag" content="tidyverse" />
<meta property="article:tag" content="causal inference" />
<meta property="article:tag" content="DAGs" />
<meta property="article:tag" content="do calculus" />
<meta property="article:tag" content="inverse probability weighting" />


    <meta itemprop="name" content="Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data">
<meta itemprop="description" content="Use R to close backdoor confounding in panel data with marginal structural models and inverse probability weights for both binary and continuous treatments"><meta itemprop="datePublished" content="2020-12-03T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-12-03T00:00:00+00:00" />
<meta itemprop="wordCount" content="5125"><meta itemprop="image" content="https://www.shagunjhaver.com/profiles/twitter-card-large.png"/>
<meta itemprop="keywords" content="r,tidyverse,causal inference,DAGs,do calculus,inverse probability weighting," />

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400;1,700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="/css/pure-and-grids-responsive.min.css">
    <link rel="stylesheet" href="/css/ath-hugo.min.fd8cb76e3e71e1679716940ae61a1383ae9edd503b072df4bc3f709182421c76.css" integrity="sha256-/Yy3bj5x4WeXFpQK5hoTg66e3VA7By30vD9wkYJCHHY=" crossorigin="anonymous" media="screen" />

    <script src="https://kit.fontawesome.com/f9d343c40d.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">    

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png?v=dLX2MbQJLG">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png?v=dLX2MbQJLG">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png?v=dLX2MbQJLG">
    <link rel="manifest" href="/site.webmanifest?v=dLX2MbQJLG">
    <link rel="mask-icon" href="/safari-pinned-tab.svg?v=dLX2MbQJLG" color="#cf4446">
    <link rel="shortcut icon" href="/favicon.ico?v=dLX2MbQJLG">
    <meta name="msapplication-TileColor" content="#170c3a">
    <meta name="theme-color" content="#170c3a">

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-527449-5', 'auto');
      ga('send', 'pageview');
    </script>
</head>

<body>

    <div id="layout" class="pure-g">
        <div id="sidebar" class="pure-u-1 pure-u-md-1-4">
            <header>
                <h1 class="title"><a href="/">Shagun Jhaver</a></h1>
                <h2 class="minibio">Social computing, CSCW, HCI, content moderation, and online harassment</h2>

                <nav id="main-nav">
                    <ul class="nav-list">
                        <li class="nav-item">
                            <a class="nav-link" href="/">About</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/cv/">CV</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/research/">Research</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/teaching/">Teaching</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/news/">News</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/now/">Now</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/work-with-me/">Work with me!</a>
                        </li>
                    </ul>
                </nav>
            </header>

        </div> 
    
        <div id="content" class="pure-u-1 pure-u-md-3-4">
        
  <section>
    <article class="content-single">
        <header class="post-header">
            <h1 class="post-title">Generating inverse probability weights for marginal structural models with time-series cross-sectional panel data</h1>

            <div class="post-meta pure-g">
                <div class="pure-u-1-2">
                    <span class="posted-on">
                        <i class="far fa-calendar-alt" aria-hidden="true"></i>
                        <time datetime='2020-12-03T00:00:00Z'>
                            Thursday, December 3, 2020
                        </time>
                    </span>
                </div>
                <div class="reading-time pure-u-1-2">
                    <i class="far fa-clock" aria-hidden="true"></i>
                    25-minute read
                </div>
            </div>
        </header>
    
        <p>In <a href="/blog/2020/12/01/ipw-binary-continuous/">my post on generating inverse probability weights for both binary and continuous treatments</a>, I mentioned that I’d eventually need to figure out how to deal with more complex data structures and causal models where treatments, outcomes, and confounders vary over time. Instead of adjusting for DAG confounding with inverse probability weights, we need to use something called marginal structural models (MSMs) to make adjustments that account for treatment and outcome history and other time structures. This is complex stuff and social science hasn’t done much with it (but it’s been a common approach in epidemiology).</p>
<p>This post is my first attempt at teaching myself how to do this stuff. As I note at the end in the <a href="#important-caveats">caveats section</a>, there might be (surely are!) mistakes. Please correct them!</p>
<h2 id="contents----omit-in-toc---">Contents <!-- omit in toc --></h2>
<ul>
<li><a href="#dags-and-time-series-cross-sectional-tscs-data">DAGs and time-series cross-sectional (TSCS) data</a></li>
<li><a href="#marginal-structural-models">Marginal structural models</a></li>
<li><a href="#simulated-time-series-cross-sectional-data">Simulated time-series cross-sectional data</a></li>
<li><a href="#marginal-structural-model-with-a-binary-treatment">Marginal structural model with a binary treatment</a>
<ul>
<li><a href="#naive-estimate-without-weights">Naive estimate without weights</a></li>
<li><a href="#manual-weights">Manual weights</a></li>
<li><a href="#weights-with-the-ipw-package">Weights with the <strong>ipw</strong> package</a></li>
</ul>
</li>
<li><a href="#marginal-structural-model-with-a-continuous-treatment">Marginal structural model with a continuous treatment</a>
<ul>
<li><a href="#naive-estimate-without-weights-1">Naive estimate without weights</a></li>
<li><a href="#manual-weights-1">Manual weights</a></li>
<li><a href="#weights-with-the-ipw-package-1">Weights with the <strong>ipw</strong> package</a></li>
</ul>
</li>
<li><a href="#important-caveats">Important caveats!</a></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">library</span>(tidyverse)
<span style="color:#a6e22e">library</span>(lme4)  <span style="color:#75715e"># For mixed models</span>
<span style="color:#a6e22e">library</span>(fixest)  <span style="color:#75715e"># For fixed effects models</span>
<span style="color:#a6e22e">library</span>(broom)
<span style="color:#a6e22e">library</span>(broom.mixed)  <span style="color:#75715e"># For tidying mixed models</span>
<span style="color:#a6e22e">library</span>(ggdag)
<span style="color:#a6e22e">library</span>(dagitty)
<span style="color:#a6e22e">library</span>(ipw)
</code></pre></div><h2 id="dags-and-time-series-cross-sectional-tscs-data">DAGs and time-series cross-sectional (TSCS) data</h2>
<p>Let’s pretend that we’re interested in the causal effect of a policy in a country on a country’s happiness. We’ll work with two different policies: whether a country implements a 6-hour workday (like <a href="https://www.forbes.com/sites/jackkelly/2020/01/08/finlands-prime-ministers-aspirational-goal-of-a-six-hour-four-day-workweek-will-this-ever-happen/?sh=79367a836384">Finland has been considering</a>), which is binary, and the number of mandated vacation days a country provides, which is continuous. Both the policy and national happiness are influenced and confounded by a few different variables: general country-specific trends, GDP per capita, level of democratization, and level of political corruption.</p>
<p>In the absence of time, this causal model is fairly straightforward:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">simple_dag <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">dagify</span>(happiness <span style="color:#f92672">~</span> policy <span style="color:#f92672">+</span> gdp_cap <span style="color:#f92672">+</span> democracy <span style="color:#f92672">+</span> corruption <span style="color:#f92672">+</span> country,
                     policy <span style="color:#f92672">~</span> gdp_cap <span style="color:#f92672">+</span> democracy <span style="color:#f92672">+</span> corruption <span style="color:#f92672">+</span> country,
                     coords <span style="color:#f92672">=</span> <span style="color:#a6e22e">list</span>(x <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(policy <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>, happiness <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>, gdp_cap <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, 
                                         democracy <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, corruption <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>, country <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>),
                                   y <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(policy <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, happiness <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, gdp_cap <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, 
                                         democracy <span style="color:#f92672">=</span> <span style="color:#ae81ff">3.3</span>, corruption <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, country <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>)),
                     exposure <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;policy&#34;</span>,
                     outcome <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;happiness&#34;</span>)

<span style="color:#a6e22e">ggdag_status</span>(simple_dag, text_col <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;black&#34;</span>) <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">guides</span>(color <span style="color:#f92672">=</span> <span style="color:#66d9ef">FALSE</span>) <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">theme_dag</span>()
</code></pre></div><p><img src="/blog/2020/12/03/ipw-tscs-msm/index_files/figure-html/dag-simple-1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>In a regular DAG setting, we can isolate the arrow between policy and happiness by statistically adjusting for all the nodes that open up backdoor relationships between them, or confound them. We can use <em>do</em>-calculus logic for that, or we can use R:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">adjustmentSets</span>(simple_dag)
<span style="color:#75715e">## { corruption, country, democracy, gdp_cap }</span>
</code></pre></div><p>Adjusting for the four confounders here is thus sufficient for closing all the backdoors and isolating the causal effect of the policy on national happiness. A standard approach to this kind of adjustment is inverse probability weighting, and I have <a href="/blog/2020/12/01/ipw-binary-continuous/">a whole post about how to do that with both binary and continuous treatments</a> (as well as <a href="/blog/2020/02/25/closing-backdoors-dags/">another post</a> and <a href="/research/chapters/heiss-causal-inference-2021/">a textbook chapter</a> with even more details and examples).</p>
<p>However, in reality, time also influences policies, happiness, and other confounders. The number of vacation days a country offers in 2019 depends a lot on the number of vacation days offered in 2018, and 2017, and 2016, and so on. Also, a country’s GDP, level of democracy, and level of corruption all depend on earlier values. Countries aren’t just getting random levels of democracy each year! Not all confounders vary with time—country remains the same every year, as do things like region and continent.</p>
<p>On top of all that, happiness in a previous year could influence the policy in the current year. If a country has lower aggregate happiness in 2016, that could influences politicians’ choice to mandate a 6-hour workday or increase vacation days in 2017 or 2018.</p>
<p>We need to incorporate time into our simple DAG. Because we’re adding a bunch more nodes, I’m going to collapse the time-varying confounders (GDP per capita, democracy, and corruption) and time-invariant confounders (just country here) into single separate nodes. To account for time, I add <code>\(t\)</code> subscripts: <code>\(t\)</code> represents the current year, <code>\(t - 1\)</code> (<code>t_m1</code> in the graph) represents the previous year, <code>\(t - 2\)</code> represents two years earlier, and so on.</p>
<p>Here’s what this looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">time_dag <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">dagify</span>(happiness_t <span style="color:#f92672">~</span> policy_t <span style="color:#f92672">+</span> varying_confounders_t <span style="color:#f92672">+</span> happiness_tm1 <span style="color:#f92672">+</span> nonvarying_confounders,
                   policy_t <span style="color:#f92672">~</span> varying_confounders_t <span style="color:#f92672">+</span> happiness_tm1 <span style="color:#f92672">+</span> policy_tm1 <span style="color:#f92672">+</span> nonvarying_confounders,
                   varying_confounders_t <span style="color:#f92672">~</span> happiness_tm1 <span style="color:#f92672">+</span> varying_confounders_tm1 <span style="color:#f92672">+</span> nonvarying_confounders,
                   happiness_tm1 <span style="color:#f92672">~</span> policy_tm1 <span style="color:#f92672">+</span> varying_confounders_tm1 <span style="color:#f92672">+</span> nonvarying_confounders,
                   policy_tm1 <span style="color:#f92672">~</span> varying_confounders_tm1 <span style="color:#f92672">+</span> nonvarying_confounders,
                   varying_confounders_tm1 <span style="color:#f92672">~</span> nonvarying_confounders,
                   coords <span style="color:#f92672">=</span> <span style="color:#a6e22e">list</span>(x <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(happiness_t <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>, policy_t <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, varying_confounders_t <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, 
                                       happiness_tm1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, policy_tm1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>, varying_confounders_tm1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>,
                                       nonvarying_confounders <span style="color:#f92672">=</span> <span style="color:#ae81ff">2.5</span>),
                                 y <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(happiness_t <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, policy_t <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, varying_confounders_t <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>, 
                                       happiness_tm1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, policy_tm1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, varying_confounders_tm1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>,
                                       nonvarying_confounders <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>)),
                   exposure <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;policy_t&#34;</span>,
                   outcome <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;happiness_t&#34;</span>)

<span style="color:#a6e22e">ggdag_status</span>(time_dag, text_col <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;black&#34;</span>) <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">guides</span>(color <span style="color:#f92672">=</span> <span style="color:#66d9ef">FALSE</span>) <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">theme_dag</span>()
</code></pre></div><p><img src="/blog/2020/12/03/ipw-tscs-msm/index_files/figure-html/dag-complex-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Phew. That’s bananas. And that’s just for one time period. Technically there are also nodes from <code>\(t - 2\)</code> and <code>\(t - 3\)</code> and so on that influence <code>\(t - 1\)</code>. Figure 2 from <a href="#ref-BlackwellGlynn:2018">Blackwell and Glynn</a> (<a href="#ref-BlackwellGlynn:2018">2018</a>) shows a similar structure with previous time periods (though they don’t have an arrow from <code>\(Y_{t-1}\)</code> to <code>\(Y\)</code>):</p>
<p><img src="blackwell-glynn-fig-2.png" alt="Figure 2 from Blackwell and Glynn (2018)"></p>
<p>All we care about in this situation is the single arrow between <code>policy_t</code> and <code>happiness_t</code>. (There are ways of looking at other arrows, like the effect of <code>policy_tm1</code> on <code>happiness_t</code>, but we won’t try to measure those here. <a href="#ref-BlackwellGlynn:2018">Blackwell and Glynn</a> (<a href="#ref-BlackwellGlynn:2018">2018</a>) show how to do that.)</p>
<p>We can use <em>do</em>-calculus logic to see what nodes need to be adjusted for to isolate that arrow:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">adjustmentSets</span>(time_dag)
<span style="color:#75715e">## { happiness_tm1, nonvarying_confounders, varying_confounders_t }</span>
</code></pre></div><p>According to this, we should adjust for time variant confounders in the current year, happiness in the previous year, and nonvarying confounders like country. <em>However</em>, this won’t be completely accurate because the previous history matters. In general, situations where treatments, confounders, and outcomes vary over time, adjustment approaches like inverse probability weighting will be biased and incorrect.</p>
<h2 id="marginal-structural-models">Marginal structural models</h2>
<p>To account for this time structure, we can instead use something called marginal structural models (MSMs) to make DAG adjustments. These have been used widely in epidemiology, and there are some really great and accessible overviews of the method here:</p>
<ul>
<li>Chapter 12 in <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">Miguel A. Hernán and James M. Robins, <em>Causal Inference: What If</em></a> (<a href="#ref-HernanRobins:2020">Hernán and Robins 2020</a>)</li>
<li>Felix Thoemmes and Anthony D. Ong, “A Primer on Inverse Probability of Treatment Weighting and Marginal Structural Models” (<a href="#ref-ThoemmesOng:2016">Thoemmes and Ong 2016</a>)</li>
<li>Stephen R. Cole and Miguel A. Hernán, “Constructing Inverse Probability Weights for Marginal Structural Models” (<a href="#ref-ColeHernan:2008">Cole and Hernán 2008</a>)</li>
<li>Kosuke Imai and Marc Ratkovic, “Robust Estimation of Inverse Probability Weights for Marginal Structural Models” (<a href="#ref-ImaiRatkovic:2015">Imai and Ratkovic 2015</a>)</li>
<li>James M. Robins, Miguel Ángel Hernán, and Babette Brumback, “Marginal Structural Models and Causal Inference in Epidemiology” (<a href="#ref-RobinsHernanBrumback:2000">Robins, Hernán, and Brumback 2000</a>)</li>
</ul>
<p>In my world of public policy and political science, though, MSMs are far rarer, even though <em><strong>tons of the data we use</strong></em> is time-series cross-sectional (TSCS) data, or panel data where each row represents a country and year (e.g. row 1 is Afghanistan in 2008, row 2 is Afghanistan in 2009, etc.) or state and year (e.g. Alabama 2015, Alabama 2016, etc.). The only paper I’ve really seen that uses MSMs in the political science world is <a href="#ref-BlackwellGlynn:2018">Blackwell and Glynn</a> (<a href="#ref-BlackwellGlynn:2018">2018</a>), which is an introduction to the topic and a call for using them more:</p>
<ul>
<li>Matthew Blackwell and Adam N. Glynn, “How to Make Causal Inferences with Time-Series Cross-Sectional Data under Selection on Observables,” (<a href="#ref-BlackwellGlynn:2018">Blackwell and Glynn 2018</a>)</li>
</ul>
<p>The basic intuition behind MSMs is similar to <a href="blog/2020/12/01/ipw-binary-continuous/">simpler inverse probability weighting</a>:</p>
<ul>
<li>Calculate weights using confounders and the time structure</li>
<li>Calculate the average treatment effect using the weights and the time structure</li>
</ul>
<p>The formula for calculating weights differs depending on if the treatment is binary or continuous, and they’re written slightly differently across those different resources listed above.</p>
<p>Here’s my version of how to calculate stabilized inverse probability weights with a binary treatment:</p>
<p><code>$$\text{Binary stabilized IPW}_{it} = \prod^t_{t = 1} \frac{P[X_{it} | \bar{X}_{i, t-1}, V_i]}{P[X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i]}$$</code></p>
<p>There are a ton of variables in this equation. Let’s go through them one at a time:</p>
<ul>
<li><code>\(i\)</code> stands for an individual (person, country, etc.)</li>
<li><code>\(t\)</code> stands for a time period (year, month, day, etc.)</li>
<li><code>\(X\)</code> stands for the observed treatment status; <code>\(X_{it}\)</code> stands for the observed treatment status of an individual at a given time. This is often written more specifically as <code>\(X_{it} = x_{it}\)</code> (see equation 1 in p. 46 in <a href="#ref-ThoemmesOng:2016">Thoemmes and Ong</a> (<a href="#ref-ThoemmesOng:2016">2016</a>), and <a href="https://rpubs.com/mbounthavong/IPTW_MSM_Tutorial">the equation at the beginning of this tutorial here</a>, for instance), but for simplicity I’ll just write it as <code>\(X_{it}\)</code>.</li>
<li><code>\(\bar{X}\)</code> stands for the individual’s history of treatment assignment (e.g. all <code>\(X\)</code> values in previous time periods)</li>
<li><code>\(Y\)</code> stands for the outcome; <code>\(Y_{it}\)</code> stands for the outcome of an individual at a given time.</li>
<li><code>\(C\)</code> stands for time <em>varying</em> confounders; because these change over time, <code>\(C\)</code> gets a <code>\(t\)</code> subscript: <code>\(C_{it}\)</code></li>
<li><code>\(V\)</code> stands for time <em>invarying</em> confounders; that’s why there’s no <code>\(t\)</code> in <code>\(V_i\)</code></li>
<li>Finally <code>\(P[\cdot]\)</code> stands for the probability distribution</li>
</ul>
<p>Here’s a more human explanation:</p>
<ul>
<li>The numerator contains the probability of the observed treatment status ($X$) at each time given the previous history of treatment ($\bar{X}$) and time <em>invariant</em> confounders ($V_i$)</li>
<li>The denominator contains the probability of the observed treatment status ($X$) at each time given the previous history of treatment ($\bar{X}$), previous outcomes ($Y_{i, t-1}$), time *varying* confounders ($C_{it}$) and time *invariant* confounders ($V_i$). The previous outcomes part ($Y_{i, t-1}$) is optional; if you think that the outcome’s previous values influence current values, and the DAG shows an arrow from <code>\(Y_{t-1}\)</code> and <code>\(Y_t\)</code>, include it.</li>
</ul>
<p>Importantly, time varying confounders ($C_{it}$) are included in the denominator only, not the numerator. The lagged outcome ($Y_{i, t-1}$), if used, also only goes in the denominator.</p>
<p>Technically the numerator can just be 1 instead of the whole <code>\(P[\cdot]\)</code> thing, but that creates unstable weights. Using <code>\(P[\cdot]\)</code> in the numerator creates stabilized weights.</p>
<p>The equation for continuous weights looks really similar:</p>
<p><code>$$\text{Continuous stabilized IPW}_{it} = \prod^t_{t = 1} \frac{f_{X | \bar{X}, V}[(X_{it} | \bar{X}_{i, t-1}, V_i); \mu_1, \sigma^2_1]}{f_{X | \bar{X}, Y, C, V}[(X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i), \mu_2, \sigma^2_2]}$$</code></p>
<p>Yikes. This is looks really complicated (and it is!), but again we can separate it into individual parts:</p>
<ul>
<li><code>\(X\)</code>, <code>\(Y\)</code>, <code>\(V\)</code>, <code>\(C\)</code>, <code>\(i\)</code>, and <code>\(t\)</code> are all the same as the binary version of the formula</li>
<li>The numerator is still the treatment, treatment history, and time invariant confounders</li>
<li>The denominator is still the treatment, treatment history, previous outcome, time varying confounders, and time invariant confounders</li>
<li>The <code>\(f_{\cdot}(\cdot)\)</code> functions are new and stand for a probability density function with a mean of <code>\(\mu\)</code> and a variance of <code>\(\sigma^2\)</code></li>
</ul>
<p>That’s a ton of information and it’s all really abstract. Let’s try this out with some simulated data</p>
<h2 id="simulated-time-series-cross-sectional-data">Simulated time-series cross-sectional data</h2>
<p>For this example, we’ll use some data I generated with the <strong>fabricatr</strong> package, which makes it really easy to build multilevel and nested structures like country- and year-level variables. The actual code to generate this is a little long, mostly because it’s heavily annotated and has a ton of intermediate variables. You can download the data here if you want to follow along with the rest of the code:</p>
<ul>
<li><a href="happiness_data.csv"><i class="fas fa-file-csv"></i> <code>happiness_data.csv</code></a></li>
<li><a href="happiness_simulation.R"><i class="fab fa-r-project"></i> <code>happiness_simulation.R</code></a></li>
</ul>
<p>It contains a bunch of different columns:</p>
<ul>
<li><code>country</code>: The country name (generated as a pronouncable 5-letter sequence (<a href="https://arxiv.org/html/0901.4016">proquint</a>) with the <a href="https://reside-ic.github.io/ids/"><strong>ids</strong> package</a>)</li>
<li><code>year</code>: The year</li>
<li><code>vacation_days</code>: The number of mandated vacation days. This is a treatment variable.</li>
<li><code>policy</code>: An indicator for whether a country has passed a policy that mandates a 6-hour workday. This is another treatment variable</li>
<li><code>happiness_vacation</code>: The level of happiness in a country, on a scale of 1–100 (more happiness = higher values). This is the outcome when using <code>vacation_days</code> as the treatment.</li>
<li><code>happiness_policy</code>: The level of happiness in a country. This is the outcome when using <code>policy</code> as the treatment.</li>
<li><code>log_populuation</code>: Logged population</li>
<li><code>log_gdp</code>: Logged GDP</li>
<li><code>gdp</code>: GDP</li>
<li><code>population</code>: Population</li>
<li><code>gdp_cap</code>: GDP per capita</li>
<li><code>log_gdp_cap</code>: Logged GDP per capita</li>
<li><code>democracy</code>: The country’s level of democracy, on a scale of 1–100 (more democratic = higher values)</li>
<li><code>corruption</code>: The level of political corruption in a country, on a scale of 1–100 (more corrupt = higher values)</li>
<li><code>lag_*</code>: Lagged versions of a bunch of different columns</li>
</ul>
<p>And here’s what the actual data looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">happiness_data <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">read_csv</span>(<span style="color:#e6db74">&#34;happiness_data.csv&#34;</span>)

<span style="color:#a6e22e">glimpse</span>(happiness_data)
<span style="color:#75715e">## Rows: 1,520</span>
<span style="color:#75715e">## Columns: 18</span>
<span style="color:#75715e">## $ country                &lt;chr&gt; &#34;Mimim&#34;, &#34;Mimim&#34;, &#34;Mimim&#34;, &#34;Mimim&#34;, &#34;Mimim&#34;, &#34;Mimim&#34;, &#34;M…</span>
<span style="color:#75715e">## $ year                   &lt;dbl&gt; 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 20…</span>
<span style="color:#75715e">## $ vacation_days          &lt;dbl&gt; 12, 14, 16, 17, 18, 20, 21, 22, 24, 25, 9, 11, 13, 14, 1…</span>
<span style="color:#75715e">## $ policy                 &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,…</span>
<span style="color:#75715e">## $ happiness_vacation     &lt;dbl&gt; 43.2, 45.1, 52.7, 52.7, 53.5, 61.4, 63.1, 66.1, 71.4, 73…</span>
<span style="color:#75715e">## $ happiness_policy       &lt;dbl&gt; 36.9, 40.6, 44.3, 46.3, 54.3, 58.4, 54.7, 59.1, 67.6, 59…</span>
<span style="color:#75715e">## $ log_population         &lt;dbl&gt; 17.4, 17.4, 17.5, 17.5, 17.6, 17.6, 17.7, 17.7, 17.8, 17…</span>
<span style="color:#75715e">## $ log_gdp                &lt;dbl&gt; 23.1, 23.2, 23.3, 23.4, 23.5, 23.6, 23.7, 23.8, 23.9, 24…</span>
<span style="color:#75715e">## $ gdp                    &lt;dbl&gt; 1.06e+10, 1.18e+10, 1.27e+10, 1.48e+10, 1.57e+10, 1.78e+…</span>
<span style="color:#75715e">## $ population             &lt;dbl&gt; 36049651, 37745007, 39520093, 41378659, 43324629, 453621…</span>
<span style="color:#75715e">## $ gdp_cap                &lt;dbl&gt; 293, 313, 321, 358, 361, 392, 434, 446, 483, 528, 5750, …</span>
<span style="color:#75715e">## $ log_gdp_cap            &lt;dbl&gt; 5.68, 5.74, 5.77, 5.88, 5.89, 5.97, 6.07, 6.10, 6.18, 6.…</span>
<span style="color:#75715e">## $ democracy              &lt;dbl&gt; 56.9, 59.8, 77.5, 71.0, 76.2, 83.1, 87.3, 92.2, 100.0, 9…</span>
<span style="color:#75715e">## $ corruption             &lt;dbl&gt; 63.4, 62.9, 62.0, 60.7, 61.9, 60.4, 60.4, 57.9, 58.0, 58…</span>
<span style="color:#75715e">## $ lag_policy             &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,…</span>
<span style="color:#75715e">## $ lag_happiness_policy   &lt;dbl&gt; 36.8, 36.9, 40.6, 44.3, 46.3, 54.3, 58.4, 54.7, 59.1, 67…</span>
<span style="color:#75715e">## $ lag_vacation_days      &lt;dbl&gt; 12, 12, 14, 16, 17, 18, 20, 21, 22, 24, 9, 9, 11, 13, 14…</span>
<span style="color:#75715e">## $ lag_happiness_vacation &lt;dbl&gt; 41.5, 43.2, 45.1, 52.7, 52.7, 53.5, 61.4, 63.1, 66.1, 71…</span>
</code></pre></div><p>We’ll use this data explore two different questions:</p>
<ol>
<li><strong>Binary treatment: What is the effect of a 6-hour workday policy on national happiness?</strong></li>
<li><strong>Continuous treatment: What is the effect of the number of mandated vacation days on national happiness?</strong></li>
</ol>
<h2 id="marginal-structural-model-with-a-binary-treatment">Marginal structural model with a binary treatment</h2>
<p>Before we do anything with the binary treatment, we need to filter the data a little. Because of the nature of the data, some of the fake countries never implement the policy and have all 0s in the <code>policy</code> column. Weird things happen with the math of logistic regression if there are countries that have all 0s or all 1s for the outcome, since it’s technically impossible to predict their outcomes. That’s why <a href="https://vuorre.netlify.app/post/2019/02/18/analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/">zero-one inflated beta (ZOIB) models or hurdle models</a> are a thing—they’re two step models that first model if you do the policy at all, then model the probability of the policy if it does happen. Rather than deal with ZOIB stuff here, I made it so that all countries start with 0 for the policy (i.e. no country has the policy in the first year), and then here we filter out any countries that don’t ever implement the policy.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">happiness_binary <span style="color:#f92672">&lt;-</span> happiness_data <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">group_by</span>(country) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">mutate</span>(never_policy <span style="color:#f92672">=</span> <span style="color:#a6e22e">all</span>(policy <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>)) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">ungroup</span>() <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">filter</span>(<span style="color:#f92672">!</span>never_policy)
</code></pre></div><h3 id="naive-estimate-without-weights">Naive estimate without weights</h3>
<p>Before playing with MSMs, let’s look at what the effect of the policy is on happiness without doing any inverse probability weighting for DAG adjustment. This is what most political science and international relations and public policy papers do. This is what I did in my dissertation and what I’ve done in a bunch of working papers. The wrongness of this approach is why I’m writing this post :)</p>
<p>This is just a regular linear regression model. I could run it with <code>lm()</code>, but then a ton of country and year coefficients would be included by default in the results, so I use <code>feols()</code> from the delightful <strong>fixest</strong> package to include country and year as fixed effects. The results from <code>feols()</code> and <code>lm()</code> are identical here; <code>feols()</code> is cleaner and faster.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model_naive <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">feols</span>(happiness_policy <span style="color:#f92672">~</span> policy <span style="color:#f92672">+</span> log_gdp_cap <span style="color:#f92672">+</span> democracy <span style="color:#f92672">+</span> 
                       corruption <span style="color:#f92672">+</span> lag_happiness_policy <span style="color:#f92672">+</span> lag_policy <span style="color:#f92672">|</span> country <span style="color:#f92672">+</span> year,
                data <span style="color:#f92672">=</span> happiness_binary)
<span style="color:#a6e22e">tidy</span>(model_naive)
<span style="color:#75715e">## # A tibble: 6 x 5</span>
<span style="color:#75715e">##   term                 estimate std.error statistic  p.value</span>
<span style="color:#75715e">##   &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span>
<span style="color:#75715e">## 1 policy                  6.76     0.397      17.0  1.90e-58</span>
<span style="color:#75715e">## 2 log_gdp_cap             3.80     1.85        2.05 4.07e- 2</span>
<span style="color:#75715e">## 3 democracy               0.146    0.0218      6.71 3.01e-11</span>
<span style="color:#75715e">## 4 corruption             -0.158    0.0252     -6.26 5.31e-10</span>
<span style="color:#75715e">## 5 lag_happiness_policy    0.172    0.0449      3.82 1.40e- 4</span>
<span style="color:#75715e">## 6 lag_policy             -1.54     0.511      -3.01 2.66e- 3</span>
</code></pre></div><p>According to this, implementing a 6-hour workday is associated with a 6.8-point increase in national happiness. This is wrong though! We need to generate and use time-adjusted inverse probability weights to adjust for these confounders.</p>
<h3 id="manual-weights">Manual weights</h3>
<p>We’ll follow this formula to use confounders and previous treatments and outcomes to generate stabilized weights:</p>
<p><code>$$\text{Binary stabilized IPW}_{it} = \prod^t_{t = 1} \frac{P[X_{it} | \bar{X}_{i, t-1}, V_i]}{P[X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i]}$$</code></p>
<p>The numerator predicts the treatment using the previous treatment and time invariant confounders. We’ll use logistic regression here, but I’m like 90% sure you can do fancier things like multilevel models or machine learning or Bayes stuff:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model_num <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">glm</span>(policy <span style="color:#f92672">~</span> lag_policy <span style="color:#f92672">+</span> country, 
                 data <span style="color:#f92672">=</span> happiness_binary, family <span style="color:#f92672">=</span> <span style="color:#a6e22e">binomial</span>(link <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;logit&#34;</span>))
</code></pre></div><p>The denominator predicts the treatment using time-varying confounders, previous outcome, previous treatment, and time invariant confounders. Again we’ll use logistic regression here, but you can probably do fancier stuff too:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># There&#39;s a warning that fitted probabiltiies of 0 or 1 occurred, likely because</span>
<span style="color:#75715e"># my data is too perfect. Oh well---we&#39;ll live with it.</span>
model_denom <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">glm</span>(policy <span style="color:#f92672">~</span> log_gdp_cap <span style="color:#f92672">+</span> democracy <span style="color:#f92672">+</span> corruption <span style="color:#f92672">+</span> 
                     lag_happiness_policy <span style="color:#f92672">+</span> lag_policy <span style="color:#f92672">+</span> country, 
                   data <span style="color:#f92672">=</span> happiness_binary, family <span style="color:#f92672">=</span> <span style="color:#a6e22e">binomial</span>(link <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;logit&#34;</span>))

<span style="color:#75715e"># This also works if you use fixest::feglm() for country fixed effects</span>
<span style="color:#75715e"># model_denom &lt;- feglm(policy ~ log_gdp_cap + democracy + corruption +</span>
<span style="color:#75715e">#                        lag_happiness_policy + lag_policy | country,</span>
<span style="color:#75715e">#                      data = happiness_binary, family = binomial(link = &#34;logit&#34;))</span>
</code></pre></div><p>Finally we need to use the results from the numerator and denominator to construct the weights following the equation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">happiness_binary_weights <span style="color:#f92672">&lt;-</span> happiness_binary <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#75715e"># Propensity scores from the models</span>
  <span style="color:#a6e22e">mutate</span>(propensity_num <span style="color:#f92672">=</span> model_num<span style="color:#f92672">$</span>fitted.values,
         propensity_denom <span style="color:#f92672">=</span> model_denom<span style="color:#f92672">$</span>fitted.values) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#75715e"># Probability of observed outcome</span>
  <span style="color:#a6e22e">mutate</span>(propensity_num_outcome <span style="color:#f92672">=</span> <span style="color:#a6e22e">ifelse</span>(policy <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>, propensity_num, <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> propensity_num),
         propensity_denom_outcome <span style="color:#f92672">=</span> <span style="color:#a6e22e">ifelse</span>(policy <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>, propensity_denom, <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> propensity_denom)) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#75715e"># Numerator / denominator</span>
  <span style="color:#a6e22e">mutate</span>(weights_no_time <span style="color:#f92672">=</span> propensity_num_outcome <span style="color:#f92672">/</span> propensity_denom_outcome) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#75715e"># Calculate the cumulative product of the weights within each country</span>
  <span style="color:#a6e22e">group_by</span>(country) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">mutate</span>(ipw <span style="color:#f92672">=</span> <span style="color:#a6e22e">cumprod</span>(weights_no_time)) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">ungroup</span>()

happiness_binary_weights <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">select</span>(country, year, policy, happiness_policy, ipw) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">head</span>()
<span style="color:#75715e">## # A tibble: 6 x 5</span>
<span style="color:#75715e">##   country  year policy happiness_policy   ipw</span>
<span style="color:#75715e">##   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;</span>
<span style="color:#75715e">## 1 Mimim    2010      0             36.9 0.800</span>
<span style="color:#75715e">## 2 Mimim    2011      0             40.6 0.640</span>
<span style="color:#75715e">## 3 Mimim    2012      0             44.3 0.516</span>
<span style="color:#75715e">## 4 Mimim    2013      0             46.3 0.486</span>
<span style="color:#75715e">## 5 Mimim    2014      1             54.3 0.116</span>
<span style="color:#75715e">## 6 Mimim    2015      1             58.4 0.116</span>
</code></pre></div><p>Finally we’ll use those weights in a regression model to estimate the average treatment effect (ATE) of the policy on happiness. We need to use a model that accounts for the year and country panel structure for this. In every tutorial I’ve seen online, people use <code>geeglm()</code> from the <a href="https://cran.r-project.org/package=geepack"><strong>geepack</strong> package</a>, which lets you specify country and year dimensions in generalized estimating equations. These feel an awful lot like mixed models with random country/year effects. There’s some useful discussion and useful links about the differences between GEE models and multilevel models <a href="https://twitter.com/andrewheiss/status/1317634713935380480">in this Twitter thread here</a>. For the sake of this example, I’ll use multilevel models since I’m more familiar with them, and because you can build Bayesian ones with the <a href="https://paul-buerkner.github.io/brms/"><strong>brms</strong> package</a>; I have yet to find a Bayesian flavor of GEEs.</p>
<p>In the outcome model, we include the previous treatment history and the invariant confounders (<code>country</code>, which I include as a random effect). To account for the time structure in the data, I also include a year random effect.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model_ate_binary <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lmer</span>(happiness_policy <span style="color:#f92672">~</span> policy <span style="color:#f92672">+</span> lag_policy <span style="color:#f92672">+</span> 
                           (<span style="color:#ae81ff">1</span> <span style="color:#f92672">|</span> country) <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">|</span> year), 
                  data <span style="color:#f92672">=</span> happiness_binary_weights, weights <span style="color:#f92672">=</span> ipw)
<span style="color:#a6e22e">tidy</span>(model_ate_binary, effects <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;fixed&#34;</span>)
<span style="color:#75715e">## # A tibble: 3 x 5</span>
<span style="color:#75715e">##   effect term        estimate std.error statistic</span>
<span style="color:#75715e">##   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span>
<span style="color:#75715e">## 1 fixed  (Intercept)    51.9      1.26      41.2 </span>
<span style="color:#75715e">## 2 fixed  policy          7.64     0.510     15.0 </span>
<span style="color:#75715e">## 3 fixed  lag_policy     -1.30     0.448     -2.91</span>
</code></pre></div><p>Voila! After adjusting for time-varying confounders and previous treatment history, the 6-hour workday policy <em>causes</em> an increase of 7.6 happiness points, on average. This is actually the effect that I built into the data. It worked!</p>
<p>However, I’m still not 100% confident that it did work. There are a lot of different moving parts here, and I’m not sure I have the right covariates in the right place (like in the outcome model, I’m fairly certain the model should be <code>happiness_policy ~ policy + lag_policy</code>, but I’m not sure).</p>
<p>Also the standard errors in this outcome model are wrong and have to be adjusted, either with fancy math or with bootstrapping (<a href="#ref-BlackwellGlynn:2018">Blackwell and Glynn</a> (<a href="#ref-BlackwellGlynn:2018">2018</a>) use boostrapping).</p>
<p>But still, this is really neat.</p>
<h3 id="weights-with-the-ipw-package">Weights with the <strong>ipw</strong> package</h3>
<p>Instead of manually doing all the math to generate the weights, we can use the <code>ipwtm()</code> function from the <a href="https://cran.r-project.org/package=ipw"><strong>ipw</strong> package</a> to do it for us. We still specify a numerator and denominator, but the function takes care of the rest of the math. The numbers are the same.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># ipwtm() can&#39;t handle tibbles! Force the data to be a data.frame</span>
weights_binary_ipw <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">ipwtm</span>(
  exposure <span style="color:#f92672">=</span> policy,
  family <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;binomial&#34;</span>,
  link <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;logit&#34;</span>,
  <span style="color:#75715e"># Time invariant stuff</span>
  numerator <span style="color:#f92672">=</span> <span style="color:#f92672">~</span> lag_policy <span style="color:#f92672">+</span> country,
  <span style="color:#75715e"># All confounders</span>
  denominator <span style="color:#f92672">=</span> <span style="color:#f92672">~</span> log_gdp_cap <span style="color:#f92672">+</span> democracy <span style="color:#f92672">+</span> corruption <span style="color:#f92672">+</span> 
    lag_happiness_policy <span style="color:#f92672">+</span> lag_policy <span style="color:#f92672">+</span> country,
  id <span style="color:#f92672">=</span> country,
  timevar <span style="color:#f92672">=</span> year,
  type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;all&#34;</span>,
  data <span style="color:#f92672">=</span> <span style="color:#a6e22e">as.data.frame</span>(happiness_binary)
)

<span style="color:#75715e"># They&#39;re the same!</span>
<span style="color:#a6e22e">head</span>(weights_binary_ipw<span style="color:#f92672">$</span>ipw.weights)
<span style="color:#75715e">## [1] 0.800 0.640 0.516 0.486 0.116 0.116</span>
<span style="color:#a6e22e">head</span>(happiness_binary_weights<span style="color:#f92672">$</span>ipw)
<span style="color:#75715e">## [1] 0.800 0.640 0.516 0.486 0.116 0.116</span>
</code></pre></div><p>This <code>weights_binary_ipw</code> object contains a bunch of other information too, but all we really care about here is what’s in the <code>ipw.weights</code> slot. We can add those weights as a column in a dataset and run the outcome model, which will give us the same ATE as before (unsurprisingly, since they’re identical). Technically we don’t need to add a new column with the weights—the model will work if they’re a standalone vector—but I don’t like mixing data frames and standalone vectors and prefer to keep everything in one nice object.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">happiness_binary_ipw <span style="color:#f92672">&lt;-</span> happiness_binary <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">mutate</span>(ipw <span style="color:#f92672">=</span> weights_binary_ipw<span style="color:#f92672">$</span>ipw.weights)

model_ate_binary_ipw <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lmer</span>(happiness_policy <span style="color:#f92672">~</span> policy <span style="color:#f92672">+</span> lag_policy <span style="color:#f92672">+</span> 
                               (<span style="color:#ae81ff">1</span> <span style="color:#f92672">|</span> country) <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">|</span> year), 
                             data <span style="color:#f92672">=</span> happiness_binary_ipw, weights <span style="color:#f92672">=</span> ipw)
<span style="color:#a6e22e">tidy</span>(model_ate_binary_ipw, effects <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;fixed&#34;</span>)
<span style="color:#75715e">## # A tibble: 3 x 5</span>
<span style="color:#75715e">##   effect term        estimate std.error statistic</span>
<span style="color:#75715e">##   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span>
<span style="color:#75715e">## 1 fixed  (Intercept)    51.9      1.26      41.2 </span>
<span style="color:#75715e">## 2 fixed  policy          7.64     0.510     15.0 </span>
<span style="color:#75715e">## 3 fixed  lag_policy     -1.30     0.448     -2.91</span>
</code></pre></div><h2 id="marginal-structural-model-with-a-continuous-treatment">Marginal structural model with a continuous treatment</h2>
<p>Here our main question is what the causal effect of mandated vacation time is on national happiness. This treatment is continuous—days of vacation. We don’t need to worry about having all 1s or all 0s and worry about zero-one inflated models or anything, since the treatment varies a lot across all countries and years.</p>
<h3 id="naive-estimate-without-weights-1">Naive estimate without weights</h3>
<p>As before, we’ll look at the effect of vacation time is on happiness without any weights. Again, this is the approach in like a billion political science papers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model_naive <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">feols</span>(happiness_vacation <span style="color:#f92672">~</span> vacation_days <span style="color:#f92672">+</span> log_gdp_cap <span style="color:#f92672">+</span> democracy <span style="color:#f92672">+</span> 
                       corruption <span style="color:#f92672">+</span> lag_happiness_vacation <span style="color:#f92672">+</span> lag_vacation_days <span style="color:#f92672">|</span> country <span style="color:#f92672">+</span> year,
                data <span style="color:#f92672">=</span> happiness_data)
<span style="color:#a6e22e">tidy</span>(model_naive)
<span style="color:#75715e">## # A tibble: 6 x 5</span>
<span style="color:#75715e">##   term                   estimate std.error statistic  p.value</span>
<span style="color:#75715e">##   &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span>
<span style="color:#75715e">## 1 vacation_days            2.12      0.129      16.4  1.85e-55</span>
<span style="color:#75715e">## 2 log_gdp_cap              1.35      0.226       5.98 2.83e- 9</span>
<span style="color:#75715e">## 3 democracy                0.0516    0.0156      3.31 9.63e- 4</span>
<span style="color:#75715e">## 4 corruption              -0.0624    0.0224     -2.78 5.48e- 3</span>
<span style="color:#75715e">## 5 lag_happiness_vacation   0.559     0.148       3.76 1.74e- 4</span>
<span style="color:#75715e">## 6 lag_vacation_days       -1.35      0.382      -3.54 4.13e- 4</span>
</code></pre></div><p>Here we see that an additional day of vacation is associated with a 2.1-point increase in national happiness. Once again, this is wrong and biased, since there’s no weighting adjustment that deals with time-based confounding.</p>
<h3 id="manual-weights-1">Manual weights</h3>
<p>We’ll follow the formula for continuous stabilized weights:</p>
<p><code>$$\text{Continuous stabilized IPW}_{it} = \prod^t_{t = 1} \frac{f_{X | \bar{X}, V}[(X_{it} | \bar{X}_{i, t-1}, V_i); \mu_1, \sigma^2_1]}{f_{X | \bar{X}, Y, C, V}[(X_{it} | \bar{X}_{i, t-1}, Y_{i, t-1}, C_{it}, V_i), \mu_2, \sigma^2_2]}$$</code></p>
<p>The numerator predicts the treatment using the previous treatment and time invariant confounders. We’ll use regular old linear regression here, but again, I’m like 90% sure you can do fancier things like multilevel models or machine learning or Bayes stuff:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model_num <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lm</span>(vacation_days <span style="color:#f92672">~</span> lag_vacation_days <span style="color:#f92672">+</span> country, 
                data <span style="color:#f92672">=</span> happiness_data)

<span style="color:#75715e"># This multilevel model works too</span>
<span style="color:#75715e"># model_num &lt;- lmer(vacation_days ~ lag_vacation_days + (1 | country), </span>
<span style="color:#75715e">#                   data = happiness_data)</span>

<span style="color:#75715e"># Calculate the probability distribution</span>
num <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">dnorm</span>(happiness_data<span style="color:#f92672">$</span>vacation_days,
             <span style="color:#a6e22e">predict</span>(model_num),
             <span style="color:#a6e22e">sd</span>(<span style="color:#a6e22e">residuals</span>(model_num)))
</code></pre></div><p>The denominator predicts the treatment using time-varying confounders, previous outcome, previous treatment, and time invariant confounders. Again we’ll use linear regression, but you can probably do fancier stuff too:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model_denom <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lm</span>(vacation_days <span style="color:#f92672">~</span> log_gdp_cap <span style="color:#f92672">+</span> democracy <span style="color:#f92672">+</span> corruption <span style="color:#f92672">+</span> 
                    lag_happiness_vacation <span style="color:#f92672">+</span> lag_vacation_days <span style="color:#f92672">+</span> country, 
                  data <span style="color:#f92672">=</span> happiness_data)

<span style="color:#75715e"># This multilevel model works too</span>
<span style="color:#75715e"># model_denom &lt;- lmer(vacation_days ~ log_gdp_cap + democracy + corruption + </span>
<span style="color:#75715e">#                     lag_happiness_vacation + lag_vacation_days + (1 | country), </span>
<span style="color:#75715e">#                   data = happiness_data)</span>

<span style="color:#75715e"># Calculate the probability distribution</span>
den <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">dnorm</span>(happiness_data<span style="color:#f92672">$</span>vacation_days,
             <span style="color:#a6e22e">predict</span>(model_denom),
             <span style="color:#a6e22e">sd</span>(<span style="color:#a6e22e">residuals</span>(model_denom)))
</code></pre></div><p>Finally we need to use the results from the numerator and denominator to build the inverse weights and calculate the cumulative product over time within each country:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># Finally, we make actual IPW weights by building the fraction</span>
happiness_data_weights <span style="color:#f92672">&lt;-</span> happiness_data <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">mutate</span>(weights_no_time <span style="color:#f92672">=</span> num <span style="color:#f92672">/</span> den) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">group_by</span>(country) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">mutate</span>(ipw <span style="color:#f92672">=</span> <span style="color:#a6e22e">cumprod</span>(weights_no_time)) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">ungroup</span>()

happiness_data_weights <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">select</span>(country, year, vacation_days, happiness_vacation, ipw) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">head</span>()
<span style="color:#75715e">## # A tibble: 6 x 5</span>
<span style="color:#75715e">##   country  year vacation_days happiness_vacation   ipw</span>
<span style="color:#75715e">##   &lt;chr&gt;   &lt;dbl&gt;         &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt;</span>
<span style="color:#75715e">## 1 Mimim    2010            12               43.2 0.142</span>
<span style="color:#75715e">## 2 Mimim    2011            14               45.1 1.50 </span>
<span style="color:#75715e">## 3 Mimim    2012            16               52.7 1.13 </span>
<span style="color:#75715e">## 4 Mimim    2013            17               52.7 0.941</span>
<span style="color:#75715e">## 5 Mimim    2014            18               53.5 0.838</span>
<span style="color:#75715e">## 6 Mimim    2015            20               61.4 0.457</span>
</code></pre></div><p>Now we can use the weights to find the ATE, just like we did with the binary version. Again, I’m using a multilevel model instead of a GEE model, which I <em>think</em> is theoretically fine and legal.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model_ate <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lmer</span>(happiness_vacation <span style="color:#f92672">~</span> vacation_days <span style="color:#f92672">+</span> lag_vacation_days <span style="color:#f92672">+</span> 
                    (<span style="color:#ae81ff">1</span> <span style="color:#f92672">|</span> country) <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">|</span> year), 
                  data <span style="color:#f92672">=</span> happiness_data_weights, weights <span style="color:#f92672">=</span> ipw)
<span style="color:#a6e22e">tidy</span>(model_ate, effects <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;fixed&#34;</span>)
<span style="color:#75715e">## # A tibble: 3 x 5</span>
<span style="color:#75715e">##   effect term              estimate std.error statistic</span>
<span style="color:#75715e">##   &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span>
<span style="color:#75715e">## 1 fixed  (Intercept)          23.4     1.82        12.9</span>
<span style="color:#75715e">## 2 fixed  vacation_days         3.48    0.0908      38.4</span>
<span style="color:#75715e">## 3 fixed  lag_vacation_days    -1.19    0.0957     -12.4</span>
</code></pre></div><p>After correctly adjusting for all the time-varying confounding, the causal effect of an additional vacation day is 3.48 happiness points, which is bigger than the naive estimate of 2.1 that we found earlier.</p>
<p>HOWEVER, this isn’t what I built into the data?? In the simulated data, I made the vacation effect be 1.7. So either I did the simulation wrong and built the effect incorrectly and it’s not actually 1.7, or I’m misspecifying the model here. I’m pretty sure that the weights themselves are fine and correct—I copied the equation and code directly from <a href="#ref-BlackwellGlynn:2018">Blackwell and Glynn</a> (<a href="#ref-BlackwellGlynn:2018">2018</a>)’s replication data, and the weights and ATE are basically the same when using <code>ipwtm()</code>. I don’t know what’s going on. :(</p>
<h3 id="weights-with-the-ipw-package-1">Weights with the <strong>ipw</strong> package</h3>
<p>It’s also possible to use the <code>ipwtm()</code> function with continuous weights, but it runs <em>incredibly slowly</em> since it uses <code>geeglm()</code> behind the scenes to build the weights.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># This takes forever! like multiple minutes</span>
weights_ipw_continuous <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">ipwtm</span>(
  exposure <span style="color:#f92672">=</span> vacation_days,
  family <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;gaussian&#34;</span>,
  corstr <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ar1&#34;</span>,
  numerator <span style="color:#f92672">=</span> <span style="color:#f92672">~</span> lag_vacation_days <span style="color:#f92672">+</span> country,  <span style="color:#75715e"># Time invariant stuff</span>
  denominator <span style="color:#f92672">=</span> <span style="color:#f92672">~</span> log_gdp_cap <span style="color:#f92672">+</span> democracy <span style="color:#f92672">+</span> corruption <span style="color:#f92672">+</span> 
    lag_happiness_vacation <span style="color:#f92672">+</span> lag_vacation_days <span style="color:#f92672">+</span> country,  <span style="color:#75715e"># All confounders</span>
  id <span style="color:#f92672">=</span> country,
  timevar <span style="color:#f92672">=</span> year,
  type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;all&#34;</span>,
  data <span style="color:#f92672">=</span> <span style="color:#a6e22e">as.data.frame</span>(happiness_data)
)
</code></pre></div><p>Because it uses GEE models for the numerator and denominator and accounts for autoregressive time structures in the data (that’s what the <code>costr = &quot;ar1&quot;</code> argument is for), the weights are not exactly the same as the ones we found using manual math, but they’re super close:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># Pretty close!</span>
<span style="color:#a6e22e">head</span>(weights_ipw_continuous<span style="color:#f92672">$</span>ipw.weights)
<span style="color:#75715e">## [1] 0.142 1.505 1.126 0.941 0.838 0.457</span>
<span style="color:#a6e22e">head</span>(happiness_data_weights<span style="color:#f92672">$</span>ipw)
<span style="color:#75715e">## [1] 0.142 1.505 1.126 0.941 0.838 0.457</span>
</code></pre></div><p>Finally we can use the weights to find the ATE. It’s basically identical to the effect we found with the manual math. (BUT STILL NOT 1.7 FOR WHATEVER REASON.)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">happiness_ipw <span style="color:#f92672">&lt;-</span> happiness_data <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">mutate</span>(ipw <span style="color:#f92672">=</span> weights_ipw_continuous<span style="color:#f92672">$</span>ipw.weights)

model_ate_ipw <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lmer</span>(happiness_vacation <span style="color:#f92672">~</span> vacation_days <span style="color:#f92672">+</span> lag_vacation_days <span style="color:#f92672">+</span> 
                        (<span style="color:#ae81ff">1</span> <span style="color:#f92672">|</span> country) <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">|</span> year), 
                      data <span style="color:#f92672">=</span> happiness_ipw, weights <span style="color:#f92672">=</span> ipw)
<span style="color:#a6e22e">tidy</span>(model_ate_ipw, effects <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;fixed&#34;</span>)
<span style="color:#75715e">## # A tibble: 3 x 5</span>
<span style="color:#75715e">##   effect term              estimate std.error statistic</span>
<span style="color:#75715e">##   &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span>
<span style="color:#75715e">## 1 fixed  (Intercept)          23.4     1.82        12.9</span>
<span style="color:#75715e">## 2 fixed  vacation_days         3.48    0.0908      38.4</span>
<span style="color:#75715e">## 3 fixed  lag_vacation_days    -1.19    0.0957     -12.4</span>
</code></pre></div><h2 id="important-caveats">Important caveats!</h2>
<p>This is just a quick practical overview of how to actually build IPWs and use MSMs. I didn’t cover any of the math behind MSMs or the assumptions behind them, their limitations, diagnostics you should do, etc. Like, weights should generally have an average of 1 and not have values that are too extreme (and if values are too extreme, you can/should truncate them).</p>
<p>ALSO I likely have something wrong here. If so, <em>let me know</em>! Download the simulated data, play with it, fix the MSMs and weights, and tell me what’s wrong. Please!</p>
<p>Consult all these resources for better details about the mechanics of these models:</p>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-BlackwellGlynn:2018" class="csl-entry">
<p>Blackwell, Matthew, and Adam N. Glynn. 2018. “How to Make Causal Inferences with Time-Series Cross-Sectional Data Under Selection on Observables.” <em>American Political Science Review</em> 112 (4): 1067–82. <a href="https://doi.org/10.1017/s0003055418000357">https://doi.org/10.1017/s0003055418000357</a>.</p>
</div>
<div id="ref-ColeHernan:2008" class="csl-entry">
<p>Cole, Stephen R., and Miguel A. Hernán. 2008. “Constructing Inverse Probability Weights for Marginal Structural Models.” <em>American Journal of Epidemiology</em> 168 (6): 656–64. <a href="https://doi.org/10.1093/aje/kwn164">https://doi.org/10.1093/aje/kwn164</a>.</p>
</div>
<div id="ref-HernanRobins:2020" class="csl-entry">
<p>Hernán, Miguel A., and James M. Robins. 2020. <em>Causal Inference: What If</em>. Boca Raton, Florida: Chapman and Hall / CRC. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/</a>.</p>
</div>
<div id="ref-ImaiRatkovic:2015" class="csl-entry">
<p>Imai, Kosuke, and Marc Ratkovic. 2015. “Robust Estimation of Inverse Probability Weights for Marginal Structural Models.” <em>Journal of the American Statistical Association</em> 110 (511): 1013–23. <a href="https://doi.org/10.1080/01621459.2014.956872">https://doi.org/10.1080/01621459.2014.956872</a>.</p>
</div>
<div id="ref-RobinsHernanBrumback:2000" class="csl-entry">
<p>Robins, James M., Miguel Ángel Hernán, and Babette Brumback. 2000. “Marginal Structural Models and Causal Inference in Epidemiology.” <em>Epidemiology</em> 11 (5): 550–60. <a href="https://doi.org/10.1097/00001648-200009000-00011">https://doi.org/10.1097/00001648-200009000-00011</a>.</p>
</div>
<div id="ref-ThoemmesOng:2016" class="csl-entry">
<p>Thoemmes, Felix, and Anthony D. Ong. 2016. “A Primer on Inverse Probability of Treatment Weighting and Marginal Structural Models.” <em>Emerging Adulthood</em> 4 (1): 40–59. <a href="https://doi.org/10.1177/2167696815621645">https://doi.org/10.1177/2167696815621645</a>.</p>
</div>
</div>

    
        <footer>
            <div class="tags">
    <i class="fas fa-tags" aria-hidden="true"></i>&ensp;
    <a href="/blog/tags/r/">r</a>
    <span class="separator">•</span>
    <a href="/blog/tags/tidyverse/">tidyverse</a>
    <span class="separator">•</span>
    <a href="/blog/tags/causal-inference/">causal inference</a>
    <span class="separator">•</span>
    <a href="/blog/tags/dags/">DAGs</a>
    <span class="separator">•</span>
    <a href="/blog/tags/do-calculus/">do calculus</a>
    <span class="separator">•</span>
    <a href="/blog/tags/inverse-probability-weighting/">inverse probability weighting</a></div>

        </footer>

        <div id="comments">
            <div id="disqus_thread"></div>
            <script type="text/javascript">
                 
                var disqus_shortname = 'andrewheisscom';
                var disqus_title = document.title;
                var disqus_url = 'https:\/\/www.shagunjhaver.com\/blog\/2020\/12\/03\/ipw-tscs-msm\/';

                 
                (function () {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
                    Disqus.</a></noscript>
        </div>
    </article>
</section>

  

<script src="/js/math-code.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>
<script>
    MathJax = {
        tex: {
            inlineMath: [
                ['$', '$'], ['\\(', '\\)']
            ],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };
</script>

        </div> 
    </div> 
    
    <div id="footer">
        <footer>
    <ul class="links">
        <li>
            <a href="mailto:shagun.jhaver@rutgers.edu" aria-label="E-mail"   >
                <i class="fa fa-envelope" aria-hidden="true"></i>
            </a>
        </li>
        <li>
            <a href="https://medium.com/@shagunjhaver" aria-label="Medium"   >
                <i class="fab fa-medium" aria-hidden="true"></i>
            </a>
        </li>
        <li>
            <a href="https://scholar.google.com/citations?user=OgtKT6UAAAAJ" aria-label="Google Scholar"   >
                <i class="ai ai-google-scholar" aria-hidden="true"></i>
            </a>
        </li>
        <li>
            <a href="https://dl.acm.org/author_page.cfm?id=99658987207" aria-label="ACM Digital Library"   >
                <i class="ai ai-acmdl-square" aria-hidden="true"></i>
            </a>
        </li>
        <li>
            <a href="https://github.com/shaguniitb" aria-label="GitHub"   >
                <i class="fab fa-github" aria-hidden="true"></i>
            </a>
        </li>
        <li>
            <a href="https://twitter.com/shagunjhaver" aria-label="Twitter"   >
                <i class="fab fa-twitter" aria-hidden="true"></i>
            </a>
        </li>
        <li>
            <a href="https://www.facebook.com/shagun.jhaver" aria-label="Facebook"   >
                <i class="fab fa-facebook" aria-hidden="true"></i>
            </a>
        </li>
        <li>
            <a href="https://www.linkedin.com/in/shagun-jhaver/" aria-label="LinkedIn"   >
                <i class="fab fa-linkedin" aria-hidden="true"></i>
            </a>
        </li>
    </ul>

    <p class="colophon"> <i class="fas fa-map-marker-alt"></i> New Brunswick, NJ </p>
    <p class="colophon">ORCID iD: <a href="https://orcid.org/0000-0002-6728-7101">0000-0002-6728-7101</a></p>

   <p class="colophon">
    This site is a derivative of <a href="https://github.com/andrewheiss/ath-hugo">ath-hugo</a> by Andrew Heiss, used under CC <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">4.0</a>.
   </p>


    <p class="colophon"><a href="https://github.com/shaguniitb/ath-hugo">Code for site</a></p>
</footer>

    </div>

</body>

</html>
